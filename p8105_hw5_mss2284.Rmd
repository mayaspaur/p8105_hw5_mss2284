---
title: "p8105_hw5_mss2284"
author: "Maya Spaur"
date: "11/6/2019"
output: github_document
---


```{r setup}
library(tidyverse)
library(ggplot2)
library(ggridges)
library(patchwork)

```


#Problem 1

Iris dataset with example subset

```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

head(iris_with_missing, 10)
tail(iris_with_missing, 10)

```

Replacing missing values with example subset

```{r}
clean_iris = function(x) {
   if (is.numeric(x)) {
   replace_na(x, mean(x, na.rm = TRUE))
   }
   else if (is.character(x))
     {replace_na(x, "virginica")}
}

output = map_dfr(.x = iris_with_missing, ~ clean_iris(.x))

head(output, 10)
tail(output, 10)
```

As demonstrated by the first 10 rows displayed, the missing numeric variables have been replaced with the mean of the non-missing values. As shown in the last 10 rows, the missing character values have been replaced with "virginica."

#Problem 2

Creating a dataframe, iterating over file names and reading in data for each subject, tidying: 


```{r, message = FALSE}
names_data =
  tibble(
  subject = list.files(path="./data")
)

file_path = "./data/"
file_names = file_path %>%
  list.files()

subject_data =
  file_names %>%
  map_dfr(function(file_name){
  read_csv(paste0(file_path, file_name))
})


study_data = cbind(names_data, subject_data) %>%
 mutate(subject = str_replace(subject, ".csv", "")) %>%
 pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observations")
```

Spaghetti plot

```{r spaghetti plot}
spaghetti_plot = 
  study_data %>%
  ggplot(aes(x = as.numeric(week), y = observations, color = subject)) +
  geom_line() +
  labs(title = "Weekly observations per subject", x = "Week", y = "Observations") + theme(legend.position="bottom")

spaghetti_plot 
```

Overall differences between the groups include that subjects in the experimental arm tended to have higher values of weekly observations than subjects in the control arm. Observations for subjects in the experimental arm tended to increase as the weeks progressed, whereas there was greater variation in increasing and decreasing tends for subjects in the control arm.


#Problem 3 


```{r}
sim_regression = function(n = 30, beta0 = 2, beta1 = 0) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 50)
  )
  
  ls_fit = lm(y ~ x, data = sim_data) %>%
     broom::tidy() %>%
     select(term, estimate, p.value)
  
}


sim_results = 
  tibble(beta1 = 0:6) %>% 
  mutate(
    output_lists = purrr::map(.x = beta1, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = purrr::map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
  
```

#Plots


Plot 1 

```{r}
Fig_1 =
sim_results %>%
  group_by(beta1) %>%
  summarize(n = n(),
            prop_sig = sum(p.value < .05)/n()*100) %>%
  ggplot(aes(x = beta1, y = prop_sig)) + geom_point() + geom_smooth(se = FALSE) + labs(x = "Value of Beta1", y = "Proportion Null Rejected", title = "Proportion of times null rejected") + theme_minimal()

Fig_1
```

This shows that the association between effect size (Beta1) is overall positively associated with power (proportion of times the null was rejected).The relationship is not linear.

Plot 2

```{r}
Fig_2 = 
  sim_results %>%
  group_by(beta1) %>%
  mutate(average_estimate = mean(estimate)) %>%
  ggplot(aes(x = beta1, y = average_estimate)) + geom_point() + geom_line() + labs(x = "Beta1", y = "Mean Estimate Beta1", title = "Avg estimate Beta1 vs. Beta1") + theme_minimal()

Fig_2
```


Plot 3

```{r}
Fig_3 = 
  sim_results %>%
  filter(p.value < .05) %>%
  group_by(beta1) %>%
  mutate(average_estimate = mean(estimate)) %>%
  ggplot(aes(x = beta1, y = average_estimate)) + geom_point() + geom_line() + labs(x = "Beta1", y = "Mean Estimate Beta1", title = "Avg estimate Beta1 in significant samples") + theme_minimal()
  
Fig_3

```

The sample average of Beta1 across tests for which the null is rejected is not approximately equal to the true value of Beta1, as seen by the difference in y axes. As demonstrated in the tables below, the null was rejected with higher proportions for beta = 5 and 6. This may have led to a difference in the sample average.

```{r}
table_1 = 
  sim_results %>%
  group_by(beta1) %>%
  summarize(n = n(),
            prop_sig = sum(p.value < .05)/n()*100) %>%
  knitr::kable()

table_1

table_2 = 
  sim_results %>%
  filter(p.value < .05) %>%
  group_by(beta1) %>%
  summarize(n = n(),
            prop_sig = sum(p.value < .05)/n()*100) %>%
  knitr::kable()

table_2

```

